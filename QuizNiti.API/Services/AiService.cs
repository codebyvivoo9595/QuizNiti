using Microsoft.AspNetCore.Http.HttpResults;
using Microsoft.IdentityModel.Tokens;
using QuizNiti.API.Data;
using QuizNiti.API.Models;
using System.Net.Http.Headers;
using System.Text.Json;

namespace QuizNiti.API.Services
{
    public class AiService
    {
        // This is a placeholder for AI-related functionalities.
        // Actual implementation would go here.
        private readonly QuizNitiContext _db;
        private readonly HttpClient _httpClient;
        private readonly IConfiguration _config;

        readonly string? hfToken ;

        public AiService(QuizNitiContext db, HttpClient httpClient, IConfiguration config)
        {
            _db = db;
            _httpClient = httpClient;
            _config = config;

             hfToken = Environment.GetEnvironmentVariable("HF_TOKEN")
              ?? _config["AISettings:HuggingFaceToken"];
        }

        public async Task<List<Questions>> AIWillGenerateQuestionsAsync(string topic, string difficulty, int count)
        {
            // Promt for logic for AI question generation

            string prompt = $@"
            Generate {count} multiple-choice current affairs questions 
            about the topic '{topic}' with '{difficulty}' difficulty.

            For each question, include:
            - The question text
            - 4 options
            - The correct answer
            - A short 'DidYouKnow' paragraph (1-2 sentences) that gives an interesting or mind-blowing fact related to that question.

            Return the result strictly in this JSON format:
            [
              {{
                ""QuestionText"": ""<question>"",
                ""Options"": [""Option A"", ""Option B"", ""Option C"", ""Option D""],
                ""CorrectAnswer"": ""<correct option>"",
                ""DidYouKnow"": ""<fascinating fact or trivia>"",
                ""Topic"": ""{topic}"",
                ""Difficulty"": ""{difficulty}""
              }}
            ]
            ";

            string provider = _config["AISettings:Provider"] ?? "Ollama";
            string aiResponse;

            if (provider.Equals("Ollama", StringComparison.OrdinalIgnoreCase))
            {
                //Use Ollama for Local Call Because Free to use but server side hosting not available yet for Free  
                aiResponse = await Call_Locally_OllamaAsync(prompt);
            }
            else 
            {
                // Use HuggingFace for Cloud-Based AI Model Hosting for server side calls it is Free
                aiResponse = await Call_HuggingFace_API_Async(prompt);
            }



            // Send the prompt to Ollama ---
            //var response = await _httpClient.PostAsJsonAsync("http://localhost:11434/api/generate", new
            //{
            //    model = "phi3", // Lite version Using Now later we can change  to llama3
            //    prompt = prompt
            //});

            //if (!response.IsSuccessStatusCode)
            //    throw new Exception("AI model failed to generate questions.");

            //var result = await response.Content.ReadAsStringAsync();

            // Extract JSON output ---
            var startIndex = aiResponse.IndexOf("[");
            var endIndex = aiResponse.LastIndexOf("]");
            var json = aiResponse.Substring(startIndex, endIndex - startIndex + 1);

            // Deserialize JSON into Question objects ---
            var DeserializeToQuestions = JsonSerializer.Deserialize<List<Questions>>(json, new JsonSerializerOptions
            {
                PropertyNameCaseInsensitive = true
            })?? new List <Questions>();

            if (DeserializeToQuestions == null || !DeserializeToQuestions.Any())
                throw new Exception("No questions generated by AI.");

            // Save to DB ---
            _db.QuestionsTable.AddRange(DeserializeToQuestions);
            await _db.SaveChangesAsync();

            return DeserializeToQuestions;


        }

        private async Task<string> Call_Locally_OllamaAsync(string prompt)
        {

            var url = _config["AISettings:OllamaUrl"];
            var response = await _httpClient.PostAsJsonAsync(url, new
            {
                model = "phi3", // Lite version Using Now later we can change  to llama3
                prompt = prompt
            });

            if (!response.IsSuccessStatusCode)
                throw new Exception("Ollama AI model failed to generate questions.");

            //var result = await response.Content.ReadAsStringAsync();
            return await response.Content.ReadAsStringAsync();

        }

        private async Task<string> Call_HuggingFace_API_Async(string prompt)
        {
            var url = _config["AISettings:HuggingFaceUrl"];
            var token = _config["AISettings:HuggingFaceApiKey"]?? hfToken;


            if (string.IsNullOrWhiteSpace(url))
                throw new Exception("HuggingFace API URL is missing from configuration.");

            if (string.IsNullOrWhiteSpace(token))
                throw new Exception("HuggingFace API token is not configured. Set it using user-secrets or environment variables.");



            //_httpClient.DefaultRequestHeaders.Authorization =
            //   new AuthenticationHeaderValue("Bearer", token);

            //var response = await _httpClient.PostAsJsonAsync(url, new
            //{
            //    inputs = prompt
            //});

            //if (!response.IsSuccessStatusCode)
            //    throw new Exception("HuggingFace AI model failed to generate questions.");

            //return await response.Content.ReadAsStringAsync();


            using var request = new HttpRequestMessage(HttpMethod.Post, url);
            request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", token);
            request.Content = JsonContent.Create(new { inputs = prompt });

            var response = await _httpClient.SendAsync(request);

            if (!response.IsSuccessStatusCode)
            {
                var error = await response.Content.ReadAsStringAsync();
                throw new Exception($"HuggingFace AI model failed to generate questions. Response: {error}");
            }

            return await response.Content.ReadAsStringAsync();

        }


    }
}
